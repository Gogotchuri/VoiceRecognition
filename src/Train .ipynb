{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import librosa\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data_cut/nino-chan-1f.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data_cut/levan-gela-4h.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data_cut/rezi-mesh-2c.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data_cut/nanuka-altu-5b.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data_cut/rezi-mesh-2a.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file_name  correct\n",
       "0    ../data_cut/nino-chan-1f.wav        1\n",
       "1   ../data_cut/levan-gela-4h.wav        4\n",
       "2    ../data_cut/rezi-mesh-2c.wav        2\n",
       "3  ../data_cut/nanuka-altu-5b.wav        5\n",
       "4    ../data_cut/rezi-mesh-2a.wav        2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_audio = '../data_cut/'\n",
    "path_to_validation = '/test_c/'\n",
    "\n",
    "def_w, def_h = 0, 0 # Default width and height of spectogram images\n",
    "num_classes = 5\n",
    "skip = 5 # Useful in signal[skip::] to shrink data size, not necessary right now\n",
    "\n",
    "# Returns correct int from file name\n",
    "def parse_number(file_path):\n",
    "  return int(''.join(ch for ch in list(file_path) if ch.isdigit()))\n",
    "\n",
    "# Return list of tuples (file_path, correct number)\n",
    "def list_of_audios(dir_path):\n",
    "  arr = glob.glob(dir_path + '*.wav')\n",
    "  random.shuffle(arr) # Shuffled data is better for training\n",
    "  return list(map(lambda x: (x, parse_number(x)), arr))\n",
    "\n",
    "df = pd.DataFrame(list_of_audios(path_to_audio), columns = ['file_name', 'correct'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 analyzed out of 680\n",
      "100 analyzed out of 680\n",
      "150 analyzed out of 680\n",
      "200 analyzed out of 680\n",
      "250 analyzed out of 680\n",
      "300 analyzed out of 680\n",
      "350 analyzed out of 680\n",
      "400 analyzed out of 680\n",
      "450 analyzed out of 680\n",
      "500 analyzed out of 680\n",
      "550 analyzed out of 680\n",
      "600 analyzed out of 680\n",
      "650 analyzed out of 680\n",
      "Different shapes: {(20, 20), (20, 31), (20, 28), (20, 24)}\n",
      "Every spectogram should be size of: (20, 31)\n"
     ]
    }
   ],
   "source": [
    "def audios_to_spectograms(file_names):\n",
    "  # Save different shapes in a set\n",
    "  x, shapes = [], set()\n",
    "\n",
    "  # Enumerate for logging\n",
    "  for indx, audio_file in enumerate(file_names):\n",
    "    # Use mfcc algorithm for spectograms\n",
    "    signal, sampling_rate = librosa.load(audio_file) \n",
    "    matrix = librosa.feature.mfcc(signal, sampling_rate)\n",
    "\n",
    "    x.append(matrix)\n",
    "    shapes.add(matrix.shape)\n",
    "    if (indx+1) % 50 == 0: print('{} analyzed out of {}'.format(indx+1, len(file_names))) # Log progress\n",
    "    \n",
    "  return x, shapes\n",
    "\n",
    "def choose_max_shapes(shapes):\n",
    "  # Iterate over shapes and choose biggest possible width and height\n",
    "  w, h = 0, 0\n",
    "  for shape in shapes:\n",
    "    w = max(w, shape[0])\n",
    "    h = max(h, shape[1])\n",
    "  return w, h\n",
    "\n",
    "matrices, shapes = audios_to_spectograms(df['file_name'])\n",
    "print('Different shapes:', shapes)\n",
    "def_w, def_h = choose_max_shapes(shapes)\n",
    "print('Every spectogram should be size of:', (def_w, def_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 20, 31)\n"
     ]
    }
   ],
   "source": [
    "def pad_spectogram(matrix):\n",
    "  # Since width is always 20 in mfcc, we only check for height difference\n",
    "  if matrix.shape[1] < def_h:\n",
    "    diff = def_h - matrix.shape[1]\n",
    "    # Append half of the difference in beginning\n",
    "    matrix = np.append(np.zeros((matrix.shape[0], diff//2), dtype=float), matrix, axis=1)\n",
    "    #Append res in the end\n",
    "    matrix = np.append(matrix, np.zeros((matrix.shape[0], diff - diff//2), dtype=float), axis=1)\n",
    "  return matrix\n",
    "\n",
    "x = np.array([pad_spectogram(matrix) for matrix in matrices])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " ...\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# One hot encode correct numbers\n",
    "y = np.matrix([[0] * (num-1) + [1] + [0] * (num_classes - num) for num in df['correct'].values])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 20, 31, 1) (680, 5) (20, 31, 1)\n"
     ]
    }
   ],
   "source": [
    "x_r = x.reshape(*x.shape, 1)\n",
    "y_r = y.reshape(*y.shape, 1)\n",
    "#x_r = (x_r - x_r.mean()) / x_r.std()\n",
    "input_shape = x_r.shape[1:]\n",
    "print(x_r.shape, y_r.shape, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
